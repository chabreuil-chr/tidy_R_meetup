---
# title: "Présentation de TidyModels"
# subtitle: "R addicts"
# author: "Clément Rieux"
# date: '22 Septembre 2022'
format: 
  revealjs:
    # footer: "[Scripts](https://github.com/clementrx/site_r)&nbsp;&nbsp;&nbsp;"
    theme: [custom.scss]
    transition: fade
    background-transition: fade
    code-copy: true
    center-title-slide: false
    highlight-style: a11y
    code-link: true
    code-overflow: wrap
    height: 1080
    width: 1600
execute: 
  eval: true
  echo: true
  freeze: auto
---

<h1>Présentation de `TidyModels`</h1>

<h2>R addict</h2>

<hr>

<h3>Clément Rieux, Consultant data science Epsilon France chez EDF</h3>

<h3>22 Septembre 2022</h3>

<br>

<h3>

![](https://raw.githubusercontent.com/rstudio/hex-stickers/master/SVG/tidymodels.svg){.absolute top="425" left="1100" width="300"}

## Tidymodels

> **tidymodels** est une collection de packages de modélisation qui est semblable à tidyverse. Créé par l'auteur de **caret** : Max Kuhn. La version 1.0.0 est disponible depuis le 13 juillet 2022.

. . .

:::: {.columns}

::: {.column width="45%"}

![](https://rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/ds.png)

:::

::: {.column width="45%"}
-   Encourager les bonnes pratiques

-   Simplifier la lecture des codes

-   Expérimenter plusieurs modèles 

-   Construire une structure stable

-   Permettre une grande variété de méthodologies

:::

::::

## Tidymodels

> **tidymodels** est une collection de packages de modélisation qui est semblable à tidyverse. Créé par l'auteur de **caret** : Max Kuhn.


```{r}
library(tidymodels) 
```

<br>

```{r}
## ── Attaching packages ─────────────────────────────────────────────────────────────────────── tidymodels 1.0.0 ──
```

<br>

```{r}
## ✔ broom        1.0.1      ✔ recipes      1.0.1 
## ✔ dials        1.0.0      ✔ rsample      1.1.0 
## ✔ dplyr        1.0.10     ✔ tibble       3.1.8 
## ✔ ggplot2      3.3.6      ✔ tidyr        1.2.0 
## ✔ infer        1.0.3      ✔ tune         1.0.0 
## ✔ modeldata    1.0.0      ✔ workflows    1.0.0 
## ✔ parsnip      1.0.1      ✔ workflowsets 1.0.0 
## ✔ purrr        0.3.4      ✔ yardstick    1.0.0 
```

<br>

```{r}
## ── Conflicts ────────────────────────────────────────────────────────────────────────── tidymodels_conflicts() ──
## ✖ purrr::discard() masks scales::discard()
## ✖ dplyr::filter()  masks stats::filter()
## ✖ dplyr::lag()     masks stats::lag()
## ✖ recipes::step()  masks stats::step()
```

## Tidymodels

> **tidymodels** est une collection de packages de modélisation qui est semblable à tidyverse. Créé par l'auteur de **caret** : Max Kuhn.


-   `rsample` : Data splitting et resampling
-   `broom` : Manipulation des données output
-   `recipes` : Préparation des données avant modélisation
-   `parsnip` : Collection de modèles
-   `yardstick` : Evaluation metrics
-   `dials/tune` : Tuning des paramètres
-   `worklows` : Création de workflow ...


## Tidymodels vs Caret

Tidymodels et Caret sont deux packages pour faire de la modélisation.

<br>

<br>

:::: {.columns}

::: {.column width="45%"}

**Caret**

- Sortie en 2008

- Utilisation des bases R

- N'est plus développé activement

:::

::: {.column width="45%"}

**Tidymodels**

- Sortie en Avril 2020 (Première version en Juillet 2018)

- Utilisation via le pipe

- En cours de développement 

:::

::::

## Comment préparer les données avec tidymodels ?

>step\_\*() 

<https://recipes.tidymodels.org/reference/>

<iframe src="https://recipes.tidymodels.org/reference/" width="100%" height="70%" frameBorder="0">

</iframe>

## Comment préparer les données avec tidymodels ?

-   `step_impute*()`
    -   `step_impute_mean()`
    -   `step_impute_linear()`
-   `step_log()`
-   `step_mutate()`
-   `step_sqrt()`
-   `step_cut()`
-   `step_dummy()`
-   `step_center()`
-   `step_normalize()`
-   `step_corr()`
-   `step_zv()`

## Comment choisir un modèle avec tidymodels ?

<br/>

::: {.incremental}
1.  Choisir un modèle
2.  Sélectionner le mode (Si nécessaire)
3.  Paramètrer le engine
:::

## 1. Choisir un modèle

Pour avoir la liste des modèles disponibles : <https://www.tidymodels.org/find/parsnip/>

<iframe src="https://www.tidymodels.org/find/parsnip/" width="100%" height="70%" frameBorder="0">

</iframe>

## 1. Choisir un modèle

La première étape consiste donc à choisir un (ou plusieurs) modèle(s).

. . .

Régression linéaire

```{r}
#| eval: false
linear_reg(penalty = NULL, mixture = NULL)
```

. . .

Decision tree

```{r}
#| eval: false
decision_tree(cost_complexity = NULL, tree_depth = NULL, min_n = NULL
)
```

. . .

Random Forest

```{r}
#| eval: false
rand_forest(mtry = NULL, trees = NULL, min_n = NULL)
```

. . .

Single layer neural network

```{r}
#| eval: false
mlp(hidden_units = NULL, penalty = NULL, dropout = NULL, epochs = NULL, activation = NULL, learn_rate = NULL)
```


## 2. Sélectionner le mode

En effet, pour clarifier le code et également ce que l'on souhaite prédire, on indique si l'on souhaite faire une `regression` ou une `classification`.

. . .

<br/>
<br/>

```{r }
#| eval: false
linear_reg() %>% 
  set_mode(mode = "regression")
```

. . .

<br/>

```{r}
#| eval: false
logistic_reg() %>% 
  set_mode(mode = "classification")
```

## 3. Paramètrer le engine

Enfin, on sélectionne un `engine` pour indiquer la méthode de calcul que l'on souhaite.

<br/>

. . .

```{r}
#| eval: false
linear_reg() %>% 
  set_engine("spark" )
```

. . .

<br>

```{r}
#| eval: false
rand_forest() %>% 
  set_engine("randomForest")
```

. . .

<br>

```{r}
#| eval: false
rand_forest() %>% 
  set_engine("ranger")
```

## Exemple de classification

### Données

Replication Data for: Using machine learning methods to predict physical activity types with Apple Watch and Fitbit data using indirect calorimetry as the criterion. Fuller Daniel, 2020. [(Lien)](https://doi.org/10.7910/DVN/ZS2Z2J)

<br>
<br>
<br>

L'objectif est de prédire depuis les données d'une montre connectée, si la personne la personne est allongée, assise, ou pratique une activté physique selon plusieurs intensité.

## Exemple de classification

Le protocol de test est composé de 40min de tapis roulant et 25min de position assise/allongée. Les données sont collectées toutes les minutes.
Nous avons 6 activités à détecter : 

-   `Lying` : Position allongée
-   `sitting` : Position assise
-   `walking self-paced` : Marcher à son rythme
-   `3 METS` : Equivalent métabolique 3 fois supérieur à un niveau assis
-   `5 METS` : Equivalent métabolique 5 fois supérieur à un niveau assis
-   `7 METS` : Equivalent métabolique 7 fois supérieur à un niveau assis

<hr>

La publication de Daniel Fuller montre que le Rotation forest models est le modèle qui donne la meilleure accuracy avec **82,6%**.


## Exemple de classification

```{r}
#| echo: false
library(tidyverse)
data <- read_csv(file = here::here("data/aw_fb_data.csv"))
data = data[,-c(1:2)]
df = data %>% filter(device == 'apple watch')
# df_fb = data %>% filter(device == 'fitbit')
opts <- options(knitr.kable.NA = "")
```

::: {style="text-align: center"}
`Données`
:::

<br>

::: {style="font-size: 0.75em"}
```{r}
#| echo: false
knitr::kable(df %>% head(6))
```
:::


## Exemple de classification

Le jeu de données étant propre, nous pouvons directement split nos données en train.test via la fonction `initial_split`

. . .


```{r}
set.seed(123)
data_split <- initial_split(df, 
                            strata = activity)

```

. . .


Que retrouve-t-on dans **data_split** ?

. . .


```{r}
data_split
```


```{r}
train_data <- training(data_split) 
test_data <- testing(data_split)
```

. . .


```{r}
nrow(train_data)
```

. . .


```{r}
nrow(test_data)
```

## Exemple de classification

Ensuite, nous allons défnir notre modèle :

. . .

```{r}
df_rec = recipe(activity ~ . , data = train_data) 
```

. . .

```{r}
df_rec
```

. . .

```{r}
summary(df_rec)
```

## Exemple de classification

Un peu de transformation ...

<br>

```{r}
df_rec = recipe(activity ~ . , data = train_data) %>% 
  step_num2factor(gender,
                  transform = function(x) x + 1,
                  levels = c('femme', 'homme')) %>% 
  step_rm(device) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  step_zv(all_numeric()) %>% 
  step_corr(all_numeric_predictors(), threshold = 0.7) 
```

## Exemple de classification

```{r}
#| code-line-numbers: "2-9"
df_rec = recipe(activity ~ . , data = train_data) %>% 
  step_num2factor(gender,
                  transform = function(x) x + 1,
                  levels = c('femme', 'homme')) %>% 
  step_rm(device) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  step_zv(all_numeric()) %>% 
  step_corr(all_numeric_predictors(), threshold = 0.7) 
```

## Exemple de classification

```{r}
#| code-line-numbers: "2-4|5|6|7|8|9"
df_rec = recipe(activity ~ . , data = train_data) %>% 
  step_num2factor(gender,
                  transform = function(x) x + 1,
                  levels = c('femme', 'homme')) %>% 
  step_rm(device) %>% 
  step_normalize(all_numeric()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_numeric()) %>% 
  step_corr(all_numeric_predictors(), threshold = 0.7) 
```

## Exemple de classification

Regardons à quoi ressemble nos données après transformation 

<br>

```{r}
encoded = df_rec %>%
  prep() %>%
  juice()
```

. . .

<br>

```{r}
#| echo: false
knitr::kable(encoded %>% head(6))
```

## Exemple de classification

On utilise modèle Random forest pour notre exemple

<br>

```{r}
rf_spec <- 
  rand_forest(trees = 200) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")
```

. . .

<br>

Création du workflow

```{r}
activity_wflow <- 
  workflow() %>% 
  add_recipe(df_rec) %>% 
  add_model(rf_spec)
```

. . .

<br>

Entraînement du modèle

```{r}
activty_fit <- 
  activity_wflow %>% 
  fit(data = train_data)
```

## Exemple Classification

```{r}
predict(activty_fit, test_data)
```

. . .

<br>

```{r}
activity_pred <- 
  augment(activty_fit, test_data)
```

. . .

<br>

```{r}
table = activity_pred %>%
  select(activity, 
         contains(".pred_"))
```

. . .

::: {style="font-size: 0.45em"}
```{r}
#| echo: false
knitr::kable(table %>% head(6))
```
:::

## Exemple Classification

### Performances

Le package `yardstick`(Dans `Tidymodels`) nous permet d'obtenir l'accuracy : 

<br>

```{r}
activity_pred %>% 
  accuracy(truth = as.factor(activity), .pred_class)
```

## Exemple Classification

### Performances


```{r}
#| fig-align: "center"
activity_pred %>% 
  select(activity, .pred_class) %>% 
  mutate(activ = as.factor(activity)) %>% 
  conf_mat(activ, .pred_class) %>% 
  autoplot(type = "heatmap")
```

## Exemple Classification

### Performances

```{r}
#| fig-align: "center"
activity_pred %>% 
  select(-.pred_class) %>% 
  roc_curve(truth = as.factor(activity), contains(".pred_")) %>% 
  autoplot()
```

## Exemple Classification

Afin de choisir certains paramètres, on peut également tuner notre modèle

```{r}
tune_spec <- rand_forest(
  mtry = tune(),
  trees = 200,
  min_n = tune()) %>%
  set_mode("classification") %>%
  set_engine("ranger")
```

. . .

<br>

```{r}
tune_wf <- workflow() %>%
  add_recipe(df_rec) %>% 
  add_model(tune_spec)
```

. . .

<br>

```{r}
#| echo: false
doParallel::registerDoParallel()
```

```{r}
set.seed(100)
cv_folds <- vfold_cv(train_data, 
                     v = 3, 
                     strata = activity) 
```

. . .

```{r}
set.seed(345)
tune_res <- tune_grid(
  tune_wf,
  resamples = cv_folds,
  grid = 20)
```

## Exemple Classification

```{r}
#| fig-align: "center"
tune_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "ACC")
```

## Exemple Classification

On ajuste notre grille de paramètres :

<br>

```{r}
rf_grid <- grid_regular(
  min_n(range = c(1, 8)),
  mtry(range = c(3, 11)),
  levels = 4) # nombre de niveaux par paramètre
```

. . .

<br>

```{r}
set.seed(456)
regular_res <- tune_grid(
  tune_wf,
  resamples = cv_folds,
  grid = rf_grid)
```

## Exemple Classification

```{r}
#| fig-align: "center"
regular_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "ACC")
```

## Exemple Classification

Sélecttion du meilleur modèle

<br>

```{r}
best_acc <- select_best(regular_res, "accuracy")

final_rf <- finalize_model(
  tune_spec,
  best_acc)
```

. . .

<br>

Finalisation du workflow

```{r}
final_wf <- workflow() %>%
  add_recipe(df_rec) %>%
  add_model(final_rf)
```

. . .

<br>

Entraînement du modèle finale

```{r}
final_res <- final_wf %>%
  last_fit(data_split) # train sur train et evalue sur test
```

## Exemple Classification

<br>

Résultat final sur notre jeu de données : 

<br>

```{r}
final_res %>% 
  collect_metrics()
```

## Exemple Classification


```{r}
#| fig-align: "center"
final_res %>% 
  collect_predictions() %>% 
  conf_mat(activity, .pred_class) %>% 
  autoplot(type = "heatmap")
```

## Exemple Classification

### Performances

```{r}
#| fig-align: "center"
final_res %>% 
  collect_predictions() %>% 
  select(-.pred_class) %>% 
  roc_curve(truth = as.factor(activity), contains(".pred_")) %>% 
  autoplot()
```

## Exemple Classification

### Enregistrement du modèle

```{r}

final_activity_model = final_res %>%
  extract_workflow()

saveRDS(final_activity_model, here::here("data", "activity_wf_model.rds"))
```

## Exemple de série temporelle

Pour les séries temporelles nous avons besoin de quelques library supplémentaires.

Concernant les données, nous avons web scrap les données historiques de la ville de Paris depuis le site [historique meteo](https://www.historique-meteo.net). =

Il s'agit des températures moyennes par jour (en degrès celsius) du 1er janvier 2010 au 31 juillet 2022.


```{r}
#| echo: false
# import des données
ts_data <- read_csv("data/paris_temp.csv") %>% 
  select(date, temp)

# format prophet
ts_data$ds = ts_data$date
ts_data$y = ts_data$temp

ts_data <- ts_data %>% 
  select(-c(date, temp))


```

::: columns
::: {.column width="45%"}
```{r}
library(modeltime)
library(timetk)
library(lubridate)
library(ggblanket)
```
:::

::: {.column width="45%"}
```{r}
#| echo: false
knitr::kable(ts_data %>% tail(6))
```
:::
:::

## Exemple de série temporelle

La library `timetk` va nous servir à créer notre split train/test

```{r}
split = time_series_split(
  ts_data,
  assess = "15 days",
  cumulative = TRUE
)
```

. . .

<br>

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
split %>% 
  tk_time_series_cv_plan() %>% 
  filter(ds > "2022-03-01") %>% 
  plot_time_series_cv_plan(ds, y)
```

## Exemple de série temporelle

Comme pour la classification nous pouvons créer une récipient pour créer des nouvelles features. On pourrait également imaginer d'ajouter des régresseurs à notre jeu de données initial afin d'améliorer notre modèle.

```{r}
recipe_spec <- recipe(y ~ ds, training(split)) %>%
  step_timeseries_signature(ds) %>%
  step_rm(contains("am.pm"), contains("hour"), contains("minute"),
          contains("second"), contains("xts")) %>%
  step_fourier(ds, period = 365, K = 5) %>%
  step_dummy(all_nominal()) 
  
table = recipe_spec %>% prep() %>% juice()
```

. . .

::: {style="font-size: 0.45em"}
```{r}
#| echo: false
knitr::kable(table %>% head(6))
```
::: 


## Exemple de série temporelle

Cependant pour les séries temporelles, une bonne pratique est de tester notre modèle sur plusieurs périodes différentes.

. . .

On va donc créer plusieurs splits de train/test

```{r}
ts_k_folds = rolling_origin(ts_data,
                            initial = 1600,
                            assess = 15, 
                            skip = 120)
```

. . .

```{r}
#| echo: false
#| fig-height: 4
#| fig-align: "center"
ts_k_folds  %>%  
  mutate(train = map(splits, analysis),
         test = map(splits, assessment)) %>%
  select(id, train, test) %>%
  pivot_longer(-id) %>%
  unnest(value) %>%
  filter(id %in% c("Slice01", "Slice10", "Slice24")) %>%
  group_by(id) %>% 
  slice(tail(row_number(), 100)) %>% 
  gg_line(x = ds,
          y = y,
          col = name,
          facet = id,
          facet_scales = 'free_x')
```

## Exemple de série temporelle

Création d'une fonction afin d'itérer un ou plusieurs modèles sur nos différents splits.

```{r}
#| code-line-numbers: "3-4|5|7-10|12-15|17-18|20-23|25-28|30-31|33-42"
tune_prophet = function(splits){
  
  train_data = analysis(splits)
  test_data = assessment(splits)
  splits_calib <- initial_time_split(train_data, prop = 0.85)
  
  model_spec_prophet_boost <- prophet_boost(
    prior_scale_changepoints = 0.01,
    prior_scale_seasonality = 5) %>%
    set_engine("prophet_xgboost") 
  
  workflow_fit_prophet_boost <- workflow() %>%
    add_recipe(recipe_spec) %>%
    add_model(model_spec_prophet_boost) %>%
    fit(training(splits_calib))
  
  calib_table = workflow_fit_prophet_boost %>%  
    modeltime_calibrate(testing(splits_calib))
  
  future_prophet_boost = calib_table %>% 
    modeltime_refit(train_data) %>% 
    modeltime_forecast(new_data = test_data,
                       actual_data = train_data)
  
  m_prophet = prophet::prophet(df = train_data,
                               seasonality.mode = 'additive',
                               changepoint.prior.scale = 0.01,
                               seasonality.prior.scale = 5)
  
  future = prophet::make_future_dataframe(m_prophet, periods = nrow(test_data),
                                          freq = 'day', include_history = FALSE)
  
  bind_rows(predict(m_prophet, future) %>% 
              select(ds, yhat) %>% 
              mutate(type = 'prophet'),
            
            future_prophet_boost %>% 
              filter(.model_desc != 'ACTUAL') %>% 
              select(ds = .index, yhat = .value) %>% 
              mutate(type = 'prophet_xgb')) %>% 
    
    left_join(test_data, by = 'ds')
  
}
```

## Exemple de série temporelle

On test nos modèles sur différentes périodes :

```{r}
ts_tune = ts_k_folds %>% mutate(result = map(splits, tune_prophet))
```

. . .

<br>

On peut donc comparer différents modèles :

<br>

::: columns
::: {.column width="50%"}
```{r}
#| echo: false
ts_tune %>% 
  select(id, result) %>% 
  unnest(result) %>% 
  group_by(id, type) %>% 
  arrange(ds) %>% 
  mutate(prev = paste0('prev_', row_number())) %>% 
  ungroup() %>% 
  select(prev, type, ds, yhat, y) %>% 
  group_by(prev, type) %>% 
  summarise(mae = mean(abs(y-yhat)),
            mape = mean(abs(y-yhat)/y)) %>% 
  ungroup() %>% 
  pivot_longer(cols=c(mae:mape), names_to="perf") %>% 
  pivot_wider(names_from = type, values_from = value) %>%
  filter(perf == 'mae') %>% 
  gg_point(x = prophet,
           y = prophet_xgb,
           title = 'MAE (Prophet vs Prophet XGB)') +
  geom_abline() 
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
ts_tune %>% 
  select(id, result) %>% 
  unnest(result) %>% 
  group_by(id, type) %>% 
  arrange(ds) %>% 
  mutate(prev = paste0('prev_', row_number())) %>% 
  ungroup() %>% 
  mutate(mae = abs(y-yhat),
            mape = abs(y-yhat)/y,
         date = as.Date(ds)) %>% 
  gg_point(x = date,
          y = mae,
          y_breaks = scales::breaks_pretty(), 
          title = 'Ecart à la prévisions sur les différents périodes (Prophet vs Prophet XGB)',
          # y_labels = scales::label_percent(),
          facet = type,
          col = type)
```
:::
:::

## Exemple de série temporelle

Une fois que nous avons trouvé un modèle performant, on l'entraine.

```{r}
model_arima = arima_reg() %>% 
  set_engine("auto_arima") %>% 
  fit(y~ds, training(split))
```

. . .

<br>

```{r}
model_prophet  = prophet_reg(
  prior_scale_changepoints = 0.01,
  prior_scale_seasonality = 5) %>% 
  set_engine("prophet") %>% 
  fit(y~ds, training(split))
```

. . .

<br>

```{r}
model_prophet_xgb  = prophet_boost(prior_scale_changepoints = 0.01,
                                   prior_scale_seasonality = 5) %>%
  set_engine("prophet_xgboost") 
  
workflow_fit_prophet_boost <- workflow() %>%
    add_model(model_prophet_xgb) %>%
    add_recipe(recipe_spec) %>%
    fit(training(split))
```

## Exemple de série temporelle

`modeltime`nous permet de créer une *table* avec plusieurs modèles afin de faciliter les comparaisons de performances.

```{r}
model_table = modeltime_table(
  model_arima,
  model_prophet,
  workflow_fit_prophet_boost
)
```

. . .

<br>

On calibre la table (= prédictions usr la période de test et calcul des résidus)

```{r}
calib_table = model_table %>% 
  modeltime_calibrate(testing(split))
```

. . .

<br>

On compare les performances : 

```{r}
calib_table %>%  modeltime_accuracy()
```

## Exemple de série temporelle


```{r}
#| echo: false
#| fig-height: 5
calib_table %>% 
  modeltime_forecast(
    new_data = testing(split),
    actual_data = ts_data,
    keep_data = T) %>% 
  filter(.index > "2022-07-10") %>% 
  plot_modeltime_forecast()
```

## Exemple de série temporelle

Pour prédire sur des données futures, on entraine le modèle une dernière fois sur l'ensemble des données : 

```{r}
future_forecast = calib_table %>% 
  modeltime_refit(ts_data) 
```

. . .

<br>

On applique notre modèle à +15 jours : 

```{r}
future_pred = future_forecast %>% 
  modeltime_forecast(
    h = '15 days',
    actual_data = ts_data
  )
```

## Exemple de série temporelle

```{r}
#| echo: false
#| fig-height: 5
future_pred %>% 
  filter(.index > "2022-06-10") %>%
  plot_modeltime_forecast()
```

## Merci !

Lien de la présentation : 
`r fontawesome::fa("github", "black")`   <https://github.com/clementrx/site_r>

<br>

Liens utiles : 

Pour étudier Tidymodel : [Tidy Modeling with R](https://www.tmwr.org/)

Pour voir des exemples d'utilisation en vidéos : 

[Julia Silge](https://www.youtube.com/c/JuliaSilge)

[Andrew Couch](https://www.youtube.com/c/AndrewCouch)
